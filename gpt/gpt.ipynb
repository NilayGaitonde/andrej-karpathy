{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "\n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 100000\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 4\n",
    "context_len = 10\n",
    "eval_interval = 1000\n",
    "n_embed = 32\n",
    "\n",
    "class LinearForward(nn.Module):\n",
    "    def __init__(self,n_embed):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_embed,4*n_embed)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.proj = nn.Linear(4*n_embed,n_embed)\n",
    "    def forward(self,X):\n",
    "        out = self.proj(self.relu(self.linear(X)))\n",
    "        return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self,head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size, bias=False)\n",
    "        self.register_buffer(\"trill\",torch.tril(torch.ones(context_len,context_len)))\n",
    "\n",
    "    def forward(self,x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) * (C**0.5)\n",
    "        wei= wei.masked_fill(self.trill[:T, :T] == 0, float('-inf'))\n",
    "        wei= F.softmax(wei, dim=-1)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self,n_head,head_size):\n",
    "        super().__init__()\n",
    "        self.mha = nn.ModuleList([Head(head_size) for _ in range(n_head)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "    def forward(self,X):\n",
    "        out = torch.cat([h(X) for h in self.mha],dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,n_embed):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHead(4, n_embed//4)\n",
    "        self.ff = LinearForward(n_embed)\n",
    "        self.prenorm = nn.LayerNorm(n_embed)\n",
    "        self.postnorm = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self,X):\n",
    "        x = self.mha(self.prenorm(X))\n",
    "        out = self.ff(self.postnorm(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.lookup_table = nn.Embedding(vocab_size,n_embed)\n",
    "        self.linear_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.positional_embeddings = nn.Embedding(context_len,n_embed)\n",
    "        self.transformer = TransformerBlock(n_embed)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        token_embed = self.lookup_table(idx)\n",
    "        pos_embed = self.positional_embeddings(torch.arange(T,device=device))\n",
    "        x = token_embed + pos_embed\n",
    "        x = self.transformer(x)\n",
    "        logits = self.linear_head(x)\n",
    "\n",
    "        B, T, C = logits.shape\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(B*T,C),targets.view(B*T))\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:,-context_len:]\n",
    "            logits,loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:] # the whole batch, the next token and the whole vocab size\n",
    "            probs = F.softmax(logits,dim=-1) # this gives us the probabilities\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next],dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sway day lonecan\n",
      "I sarse with I fits our laid that a peayclave theepong; lik me,\n",
      "In I hat his an, well ton he to theit\n",
      "LANTIO:\n",
      "Clikerere sighter layoustime pred\n",
      "Sir I stry\n",
      "Thal was chat of you sas pall crulen with to lanion for my them\n",
      "The are uss to but devenak!\n",
      "That letion:\n",
      "I becturespier me them and up suree ane of hink fage! fast wheso wer Cut think mete as mouty ry thal: and out,\n",
      "Of tharome?\n",
      "Stion the begenukakes wing oby ling deet thoul us thou datin'd go math:\n",
      "For olds.\n",
      "\n",
      "JORKET:\n",
      "\n",
      "Good,\n",
      "Andien.\n",
      "\n",
      "BOLIO:\n",
      "You buterationg ther\n",
      "EDend, mary.\n",
      "\n",
      "Unlin theremost he bear ther, if you anfing the hat younumpark.\n",
      "\n",
      "The shis he falove\n",
      "Rom PARLANA:\n",
      "O pre dot my your be.\n",
      "\n",
      "MOLALAM:\n",
      "Is twarwas berrow anten perces\n",
      "a puray, wing this brinswy, so me hen mans\n",
      "that to jed thaver\n",
      "Of the wity\n",
      "Ands sereve inturgeng cet\n",
      "LAET:\n",
      "But to Ped sur gard thou slavent why youstem, tiolf is I of you. welf, freelaterd?\n",
      "Bep loollonjus one peak,\n",
      "I feare faralm you to is good, I them\n",
      "archet!\n",
      "\n",
      "Rome ort: me on a sa's Rolds, \n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size=65)\n",
    "model.load_state_dict(torch.load(\"../models/gpt.pth\"))\n",
    "with open(\"../data/input.txt\",\"r\",encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(list(set(\"\".join(text))))\n",
    "vocab_size = len(chars)\n",
    "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "encode = lambda s:[stoi[c] for c in s]\n",
    "decode = lambda s:[itos[c] for c in s]\n",
    "print(\"\".join(decode(model.generate(context,1000)[0].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
